{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85503b00-899f-4e6b-bb7b-6c16a332147a",
   "metadata": {},
   "source": [
    "Model that accurately recognize food items from images and estimate their calorie content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56eb2c9f-8407-4a46-9574-cdfa4554e88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf  # Import TensorFlow library for deep learning tasks\n",
    "import matplotlib.image as img  # Import matplotlib for image reading\n",
    "import numpy as np  # Import NumPy for numerical operations\n",
    "from collections import defaultdict  # Import defaultdict for creating dictionaries with default values\n",
    "import collections  # Import collections module for collection data types\n",
    "from shutil import copy  # Import shutil for high-level file operations\n",
    "from shutil import copytree, rmtree  # Import shutil for directory copying and removal\n",
    "import tensorflow.keras.backend as K  # Import Keras backend functions\n",
    "from tensorflow.keras.models import load_model  # Import Keras function for loading pre-trained models\n",
    "from tensorflow.keras.preprocessing import image  # Import Keras for image preprocessing\n",
    "import matplotlib.pyplot as plt  # Import matplotlib for visualization\n",
    "import os  # Import os module for operating system functions\n",
    "import random  # Import random module for generating random numbers\n",
    "import cv2  # Import OpenCV for image processing\n",
    "from tensorflow.keras import regularizers  # Import regularizers for regularization techniques\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3  # Import pre-trained InceptionV3 model\n",
    "from tensorflow.keras.models import Sequential, Model  # Import Sequential and Model for building neural network models\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten  # Import layers for building neural network architectures\n",
    "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D, AveragePooling2D  # Import layers for building convolutional neural networks\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator  # Import ImageDataGenerator for data augmentation\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger  # Import callbacks for model saving and logging\n",
    "from tensorflow.keras.optimizers import SGD  # Import SGD optimizer for training models\n",
    "from tensorflow.keras.regularizers import l2  # Import L2 regularization\n",
    "from tensorflow import keras  # Import Keras for deep learning tasks\n",
    "from tensorflow.keras import models  # Import Keras for building neural network models\n",
    "import zipfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0720e0-23e7-437d-9dc7-27ffbbe5492d",
   "metadata": {},
   "source": [
    "dataset used(https://www.kaggle.com/datasets/dansbecker/food-101/code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95637115-c80b-4869-914c-5820f4e053bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check TensorFlow version\n",
    "print(tf._version_)\n",
    "\n",
    "# Check GPU device name\n",
    "print(tf.test.gpu_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80529999-8b31-434e-94d1-cd23248573c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /kaggle/input/food-101/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b784ea40-eb42-4496-a95a-ade91b7af832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading and extracting the dataset\n",
    "\n",
    "def get_data_extract():\n",
    "    \"\"\"\n",
    "    Check if the dataset exists, if not, download and extract it.\n",
    "    \"\"\"\n",
    "    if \"food-101\" in os.listdir():\n",
    "        print(\"Dataset exists!\")\n",
    "    else:\n",
    "        print(\"Downloading the data...\")\n",
    "        !wget http://data.vision.ee.ethz.ch/cvl/food-101.tar.gz\n",
    "        print(\"Dataset downloaded!\")\n",
    "        print(\"Extracting data..\")\n",
    "        !tar xzvf food-101.tar.gz\n",
    "        print(\"Extraction done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7aa9d18-8aa7-4656-acb8-2bfa79c39722",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_data_extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660ce3c9-095a-4cdd-8858-4ce8f0c19396",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('food-101/images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9aaf4ec-0a63-429f-a2b0-038300ab3238",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('food-101/meta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83349a4e-5a97-421e-b24f-b4f40917041b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!head food-101/meta/train.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7986b5c5-4161-4361-9423-e184766d9a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!head food-101/meta/classes.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fb4f15-ea3f-478a-acbc-53daa7ad9859",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = 17\n",
    "cols = 6\n",
    "\n",
    "# Subplot grid with specified size\n",
    "fig, ax = plt.subplots(rows, cols, figsize=(25,25))\n",
    "\n",
    "fig.suptitle(\"One random image from each class\", y=1.05, fontsize=24)\n",
    "\n",
    "data_dir = \"food-101/images/\"\n",
    "\n",
    "foods_sorted = sorted(os.listdir(data_dir))\n",
    "\n",
    "food_id = 0\n",
    "\n",
    "for i in range(rows):\n",
    "    for j in range(cols):\n",
    "        try:\n",
    "            food_selected = foods_sorted[food_id] \n",
    "            food_id += 1\n",
    "        except:\n",
    "            break\n",
    "        if food_selected == '.DS_Store':\n",
    "            continue\n",
    "        # List of images for the current food class\n",
    "        food_selected_images = os.listdir(os.path.join(data_dir, food_selected))\n",
    "        # Select a random image from the list\n",
    "        food_selected_random = np.random.choice(food_selected_images)\n",
    "        # Read and display the image\n",
    "        img = plt.imread(os.path.join(data_dir, food_selected, food_selected_random))\n",
    "        ax[i][j].imshow(img)\n",
    "        ax[i][j].set_title(food_selected, pad=10)  # Set the title of the subplot\n",
    "\n",
    "\n",
    "plt.setp(ax, xticks=[], yticks=[])\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1824cb39-3b1c-4163-8bf7-a3bfc5aa72f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(filepath, src, dest):\n",
    "    # Store image paths for each class\n",
    "    classes_images = defaultdict(list)\n",
    "    \n",
    "       with open(filepath, 'r') as txt:\n",
    "        paths = [read.strip() for read in txt.readlines()]\n",
    "        for p in paths:\n",
    "            food = p.split('/')\n",
    "            classes_images[food[0]].append(food[1] + '.jpg')\n",
    "\n",
    "    # Iterate over classes and copy images to destination folder\n",
    "    for food in classes_images.keys():\n",
    "        print(\"\\nCopying images into \", food)\n",
    "        if not os.path.exists(os.path.join(dest, food)):\n",
    "            os.makedirs(os.path.join(dest, food))\n",
    "        for i in classes_images[food]:\n",
    "            copy(os.path.join(src, food, i), os.path.join(dest, food, i))\n",
    "    print(\"Copying Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9ec3ca-a88b-4d5a-b31b-c934d02f780b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change current directory to the root directory\n",
    "%cd /\n",
    "\n",
    "print(\"Creating train data...\")\n",
    "\n",
    "# Copy images from train.txt to train directory\n",
    "prepare_data('/kaggle/input/food-101/food-101/meta/train.txt', '/kaggle/input/food-101/food-101/images', 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4ef83d-a1aa-4d58-b57d-6081f79ccea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating test data...\")\n",
    "\n",
    "# Prepare_data function to copy images from test.txt to test directory\n",
    "prepare_data('/kaggle/input/food-101/food-101/meta/test.txt', '/kaggle/input/food-101/food-101/images', 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecc2be9-f41e-47fc-a3d5-5a6b1d9aec58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train_mini and test_mini data samples\n",
    "def dataset_mini(food_list, src, dest):\n",
    "    # Check if the destination directory exists\n",
    "    if os.path.exists(dest):\n",
    "       \n",
    "        rmtree(dest)  # Removing dataset_mini (if it already exists) folders\n",
    "    # Create the destination directory\n",
    "    os.makedirs(dest)\n",
    "    \n",
    "    for food_item in food_list:\n",
    "        print(\"Copying images into\", food_item)\n",
    "        # Copy the images from the source to the destination directory for each food item\n",
    "        copytree(os.path.join(src, food_item), os.path.join(dest, food_item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8614902-b707-4a88-ada0-caa16b232cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "food_list = ['apple_pie', 'pizza', 'omelette']\n",
    "\n",
    "src_train = 'train'\n",
    "dest_train = 'train_mini'\n",
    "src_test = 'test'\n",
    "dest_test = 'test_mini'\n",
    "\n",
    "# Train_mini dataset\n",
    "dataset_mini(food_list, src_train, dest_train)\n",
    "\n",
    "# Test_mini dataset\n",
    "dataset_mini(food_list, src_test, dest_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5127a390-f626-48bc-b255-c8b40a017f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating train data folder with new classes\")\n",
    "\n",
    "dataset_mini(food_list, src_train, dest_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0849c76-2d40-4864-8377-384d13f16c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating test data folder with new classes\")\n",
    "dataset_mini(food_list, src_test, dest_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05dbe39-dc2b-4b36-a316-3921e18f5b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy(history, title):\n",
    "\n",
    " plt.title(title)\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train_accuracy', 'validation_accuracy'], loc='best')\n",
    "    plt.show()\n",
    "\n",
    "def plot_loss(history, title):\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train_loss', 'validation_loss'], loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5b4e89-e151-4f03-88b7-76058977b836",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy(history, 'FOOD101-Inceptionv3')  # Training and validation accuracy\n",
    "plot_loss(history, 'FOOD101-Inceptionv3')      # Training and validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67424519-309a-47e2-8839-97192d5f2550",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "K.clear_session()  # Clear Keras session\n",
    "model_best = load_model('best_model_3class.hdf5', compile=False)  # Load the best saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e21a89c-1818-45c7-a5f3-887709a227d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_class(model, images, show=True):\n",
    "\n",
    "    for img in images:\n",
    "        img = image.load_img(img, target_size=(299, 299)) \n",
    "        img = image.img_to_array(img)                    \n",
    "        img = np.expand_dims(img, axis=0)                        \n",
    "        img /= 255.                                       \n",
    "        pred = model.predict(img)                         \n",
    "        index = np.argmax(pred)                           # Get the index of the class with the highest probability\n",
    "        food_list.sort()                                  # Sort the list of food items\n",
    "        pred_value = food_list[index]                     # Get the predicted class label\n",
    "        \n",
    "        if show:\n",
    "            plt.imshow(img[0])                          \n",
    "            plt.axis('off')\n",
    "            plt.title(pred_value)                        # Set title as the predicted class label\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83557a82-e9bd-4c48-a581-2c2b33b3cb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_n_random_classes(n):\n",
    "    food_list = []\n",
    "    random_food_indices = random.sample(range(len(foods_sorted)), n)  # Sample n random indices\n",
    "    for i in random_food_indices:\n",
    "        food_list.append(foods_sorted[i])  # Retrieve corresponding food items\n",
    "    food_list.sort()  # Sort the list of randomly selected food classes\n",
    "    return food_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e714ac82-a2e1-4495-b14e-2e3cdc436cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 11  # Number of random food classes to select\n",
    "food_list = pick_n_random_classes(n)  # Select n random food classes\n",
    "food_list = ['apple_pie', 'beef_carpaccio', 'bibimbap', 'cup_cakes', 'foie_gras', 'french_fries', 'garlic_bread', 'pizza', 'spring_rolls', 'spaghetti_carbonara', 'strawberry_shortcake']\n",
    "print(\"These are the randomly picked food classes we will be training the model on...\\n\", food_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf718288-97d7-4301-91ed-472b9da0d8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "\n",
    "n_classes = n\n",
    "\n",
    "img_width, img_height = 299, 299\n",
    "\n",
    "train_data_dir = 'train_mini'\n",
    "validation_data_dir = 'test_mini'\n",
    "\n",
    "nb_train_samples = 8250\n",
    "nb_validation_samples = 2750\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "# Define data augmentation for training images\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "# Generate batches of augmented training and validation data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "# Load the InceptionV3 model pretrained on ImageNet without the top layer\n",
    "inception = InceptionV3(weights='imagenet', include_top=False)\n",
    "\n",
    "# Add custom top layers for classification\n",
    "x = inception.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "predictions = Dense(n, kernel_regularizer=regularizers.l2(0.005), activation='softmax')(x)\n",
    "\n",
    "\n",
    "model = Model(inputs=inception.input, outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define callbacks for model checkpointing and logging\n",
    "checkpointer = ModelCheckpoint(filepath='best_model_11class.hdf5', verbose=1, save_best_only=True)\n",
    "csv_logger = CSVLogger('history_11class.log')\n",
    "\n",
    "# Train the model\n",
    "history_11class = model.fit_generator(train_generator,\n",
    "                    steps_per_epoch=nb_train_samples // batch_size,\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps=nb_validation_samples // batch_size,\n",
    "                    epochs=30,\n",
    "                    verbose=1,\n",
    "                    callbacks=[csv_logger, checkpointer])\n",
    "\n",
    "# Save the trained model\n",
    "model.save('model_trained_11class.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcac77f-fd1b-4764-8e86-60ffada9f5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_map_11 = train_generator.class_indices\n",
    "class_map_11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c07f6e-5779-4ad6-bfb1-b5e9d7804743",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "images.append('cupcakes.jpg')\n",
    "images.append('pizza.jpg')\n",
    "images.append('springrolls.jpg')\n",
    "images.append('garlicbread.jpg')\n",
    "predict_class(model_best, images, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235663a1-dcbe-4f04-aa18-876c7fe0f6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "print(\"Loading the model..\")\n",
    "model = load_model('best_model_3class.hdf5', compile=False)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf7ae90-f8eb-4d45-9b7e-fd86a130b505",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e4b7ac-9873-47ce-ae8a-6ef7ccec28a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_names = []\n",
    "\n",
    "# Iterate through the layers of the model starting from index 1 and ending at index 10 (inclusive)\n",
    "for layer in model.layers[1:11]:\n",
    "    # Append the name of each layer to the list\n",
    "    layer_names.append(layer.name)\n",
    "\n",
    "# Print the list of layer names\n",
    "print(layer_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f88deb-4953-444b-9977-1cd69fc4a36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "food = 'applepie.jpg'\n",
    "\n",
    "# Get the activations of the model for the specified image using the defined activations_output model\n",
    "activations = get_activations(food, activations_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fcb9ec-41a1-4f07-8b70-ceb8978bab7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = layer_names.index('activation_1')\n",
    "sparse_activation = activations[ind]\n",
    "# Select the activation values of a specific filter\n",
    "a = sparse_activation[0, :, :, 13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d58f45-edf4-4373-b2a7-340fefc28a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all(np.isnan(a[j][k]) for j in range(a.shape[0]) for k in range(a.shape[1]))\n",
    "#This line checks if all elements in the array a are NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439e1c07-7670-431e-aa9c-8d33b5131536",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attribution(food):\n",
    "    # Load and preprocess the input image\n",
    "    img = image.load_img(food, target_size=(299, 299))\n",
    "    img = image.img_to_array(img) \n",
    "    img /= 255. \n",
    "\n",
    "    # Display the input image\n",
    "    f, ax = plt.subplots(1, 3, figsize=(15, 15))\n",
    "    ax[0].imshow(img)\n",
    "    ax[0].set_title(\"Input Image\")\n",
    "\n",
    "    # Expand the dimensions and predict the class probabilities\n",
    "    img = np.expand_dims(img, axis=0) \n",
    "    preds = model.predict(img)\n",
    "    class_id = np.argmax(preds[0])\n",
    "\n",
    "    # Get the class output and last convolutional layer\n",
    "    class_output = model.output[:, class_id]\n",
    "    last_conv_layer = model.get_layer(\"mixed10\")\n",
    "    # Calculate gradients and pooled gradients\n",
    "    grads = K.gradients(class_output, last_conv_layer.output)[0]\n",
    "    pooled_grads = K.mean(grads, axis=(0, 1, 2))\n",
    "    iterate = K.function([model.input], [pooled_grads, last_conv_layer.output[0]])\n",
    "    pooled_grads_value, conv_layer_output_value = iterate([img])\n",
    "\n",
    "    # Generate heatmap\n",
    "    for i in range(2048):\n",
    "        conv_layer_output_value[:, :, i] *= pooled_grads_value[i]\n",
    "    heatmap = np.mean(conv_layer_output_value, axis=-1)\n",
    "    heatmap = np.maximum(heatmap, 0)\n",
    "    heatmap /= np.max(heatmap)\n",
    "    ax[1].imshow(heatmap)\n",
    "    ax[1].set_title(\"Heat map\")\n",
    "\n",
    "    # Overlay heatmap on the original image\n",
    "    act_img = cv2.imread(food)\n",
    "    heatmap = cv2.resize(heatmap, (act_img.shape[1], act_img.shape[0]))\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "    superimposed = cv2.addWeighted(act_img, 0.6, heatmap, 0.4, 0)\n",
    "    cv2.imwrite('classactivation.png', superimposed)\n",
    "    img_act = image.load_img('classactivation.png', target_size=(299, 299))\n",
    "    ax[2].imshow(img_act)\n",
    "    ax[2].set_title(\"Class Activation\")\n",
    "    plt.show()\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffc71fb-39ee-48fb-9fde-bc5cca6a95c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Showing the class map..\")\n",
    "print(class_map_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff82921e-79ca-4161-aea6-2e012bca0baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "food = 'piepizza.jpg'\n",
    "activations = get_activations(food,activations_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443e8658-2c62-4e7a-aadc-2bbce33240f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_activations(activations, layer_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f81197e-8325-46c4-9c15-6897d6da5be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = get_attribution('piepizza.jpg')\n",
    "print(\"Here are softmax predictions..\",pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c15a3e8-4fc4-41c6-b3b6-f0c2a066123a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c4e3ab-b0f9-4531-8de8-cbe234b065ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow_from_directory(train_dir, target_size=IMAGE_SIZE, batch_size=BATCH_SIZE, class_mode='categorical')\n",
    "test_generator = test_datagen.flow_from_directory(test_dir, target_size=IMAGE_SIZE, batch_size=BATCH_SIZE, class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1461179-d2bf-4df9-bfad-6abc2b60226d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model architecture\n",
    "input_layer = Input(shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3))\n",
    "x = Conv2D(32, (3, 3), activation='relu')(input_layer)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Conv2D(128, (3, 3), activation='relu')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "output_layer = Dense(len(train_generator.class_indices), activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e41f4f-8f1c-4f40-ba56-7f12dd89eac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(input_layer, output_layer)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab21e59-1e4c-43d4-a545-8a8effbf6e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_generator, epochs=EPOCHS, validation_data=test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815b8fea-1609-4f7c-9802-608981f777f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model predictions\n",
    "def visualize_predictions(model, test_generator, num_samples=5):\n",
    "    class_names = list(test_generator.class_indices.keys())\n",
    "    sample_images, sample_labels = next(test_generator)\n",
    "    predicted_labels = model.predict(sample_images)\n",
    "    predicted_classes = np.argmax(predicted_labels, axis=1)\n",
    "\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for i in range(num_samples):\n",
    "        plt.subplot(1, num_samples, i+1)\n",
    "        plt.imshow(sample_images[i])\n",
    "        plt.title(f\"True: {class_names[np.argmax(sample_labels[i])]}, Predicted: {class_names[predicted_classes[i]]}\")\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "visualize_predictions(model, test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3a8f78-a07e-4893-bc45-a3a9167528c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calorie Estimation (Placeholder)\n",
    "def estimate_calories(food_item):\n",
    "    # Replace with your actual calorie estimation model\n",
    "    return np.random.randint(50, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bff33f-7432-48da-8388-6b3b38b0c0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(test_generator)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4cea28-9208-47fd-a6d5-4f93fce7c71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = model.predict(test_generator)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "y_true = test_generator.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc1a8b7-b859-4182-8345-e5ce99ab4670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=test_generator.class_indices.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd59eed-3dae-42fc-b809-bf82879eeb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dec0686-87f9-4c6f-b590-58ce6d1552ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"food_recognition_model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
